{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from torch import nn\n",
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data=pd.read_csv('data.csv')\n",
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(data['label'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data=pd.read_csv('data.csv')\n",
    "classes=np.sort(data['label'].drop_duplicates().values)\n",
    "classes_dict={}\n",
    "for i,cls in enumerate(classes):\n",
    "    classes_dict[str(cls)]=i\n",
    "print(len(classes_dict))\n",
    "data['label']=data['label'].map(lambda x: classes_dict[str(x)])\n",
    "\n",
    "max_len=[len(line) for line in data['text']]\n",
    "print(max(max_len))\n",
    "data.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id2label = {str(i):label for i, label in enumerate(classes)}\n",
    "label2id = {label:str(i) for i, label in enumerate(classes)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id2label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label2id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(data,preserve_index=False)\n",
    "dataset = dataset.train_test_split(test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name='sberbank-ai/ruBert-base'\n",
    "# model_name='distilbert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,model_max_length=512)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=9)\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id\n",
    "model.config._num_labels = len(id2label)  ## replacing 9 by 13\n",
    "model.config.num_labels = len(id2label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [[p for (p, l) in zip(prediction, label) if l != -100] for prediction, label in\n",
    "                        zip(predictions, labels)]\n",
    "    true_labels = [[l for (p, l) in zip(prediction, label) if l != -100] for prediction, label in\n",
    "                   zip(predictions, labels)]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    print(results)\n",
    "    return {\"precision\": results[\"overall_precision\"], \"recall\": results[\"overall_recall\"], \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# metric = load_metric(\"accuracy\")\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # if task != \"stsb\":\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    # else:\n",
    "    # predictions = predictions[:, 0]\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "epochs=4\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"test-classify-{str(time.time())}\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=epochs,\n",
    "    learning_rate=1e-3,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=2,\n",
    "    logging_strategy='steps',\n",
    "    logging_first_step=True,\n",
    "    logging_steps=5,\n",
    "    report_to='wandb',\n",
    "    # fp16=True,\n",
    "    weight_decay=1e-5,\n",
    "    dataloader_num_workers=4,\n",
    "    metric_for_best_model='accuracy'\n",
    ")\n",
    "\n",
    "# args = TrainingArguments(\n",
    "#     f\"test-classify-{str(time.time())}\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     learning_rate=1e-3,\n",
    "#     per_device_train_batch_size=batch_size,\n",
    "#     per_device_eval_batch_size=batch_size,\n",
    "#     num_train_epochs=epochs,\n",
    "#     logging_steps=10,\n",
    "#     weight_decay=1e-2,\n",
    "#     report_to='wandb'\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding='max_length')\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.evaluate(tokenized_datasets['test'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save_pretrained(\"mazur\")\n",
    "tokenizer.save_pretrained(\"mazur\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the model/tokenizer\n",
    "from transformers import AutoModelForTokenClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tokenizer\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "trainer = Trainer(model=model)\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "def pipeline_prediction(text):\n",
    "    df=pd.DataFrame({'text':[text]})\n",
    "    dataset = Dataset.from_pandas(df,preserve_index=False)\n",
    "    tokenized_datasets = dataset.map(tokenize_function)\n",
    "    raw_pred, _, _ = trainer.predict(tokenized_datasets)\n",
    "    return(raw_pred[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}